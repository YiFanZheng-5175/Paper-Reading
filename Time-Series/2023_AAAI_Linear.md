# Are Transformers Effective for Time Series Forecasting?

>领域：时间序列预测
>发表在：AAAI 2023
>模型名字：Linear  
>文章链接：[Are Transformers Effective for Time Series Forecasting?](https://arxiv.org/abs/2205.13504)  
>代码仓库：[https://github.com/cure-lab/LTSF-Linear](https://github.com/cure-lab/LTSF-Linear)  
![20250316210925](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316210925.png)

## 一、研究背景与问题提出

### 1.1 研究现状

时间序列在当今数据驱动的世界中无处不在。鉴于历史数据，时间序列预测（TSF）是一项长期存在的任务，具有广泛的应用，包括但不限于交通流量估计、能源管理和金融投资。在过去的几十年中，时间序列预测解决方案经历了从传统统计方法（例如 ARIMA [1]）和机器学习技术（例如 GBRT [11]）到基于深度学习的解决方案的发展，例如循环神经网络 [15] 和时间卷积网络 [3,17]。

Transformer[26]可以说是最成功的序列建模架构，在各种应用中表现出无与伦比的性能，例如自然语言处理（NLP）[7]、语音识别[8]和计算机视觉[19,29]。最近，基于 Transformer 的时间序列分析解决方案也大量涌现，如[27]中所调查的那样。最值得注意的模型主要关注探索较少且具有挑战性的长期时间序列预测（LTSF）问题，包括 LogTrans[16]（NeurIPS 2019）、Informer[30]（AAAI 2021 最佳论文）、Autoformer[28]（NeurIPS 2021）、Pyraformer[18]（ICLR 2022 oral）、Triformer[5]（IJCAI 2022）以及最近的 FEDformer[31]（ICML 2022）。

Transformer 的主要工作动力来自其多头自注意力机制，该机制在提取长序列（例如文本中的单词或图像中的二维补丁）中元素之间的语义相关性方面具有卓越的能力。然而，自注意力在一定程度上是排列不变的且“anti-order”的。虽然使用各种类型的位置编码技术可以保留一些顺序信息，但在它们之上应用自注意力后仍然不可避免地会有时间信息损失。对于语义丰富的应用（如自然语言处理）来说，这通常不是一个严重的问题，例如，即使我们重新排列句子中的一些单词，句子的语义含义在很大程度上也得以保留。但是，在分析时间序列数据时，数值数据本身通常缺乏语义，我们主要对建模连续点集中的时间变化感兴趣。也就是说，顺序本身起着最关键的作用。因此，我们提出了以下有趣的问题：Transformer对于长期时间序列预测真的有效吗？

此外，虽然现有的基于 Transformer 的长期时间序列解决方案在实验中已证明比传统方法在预测准确性上有了相当大的提高。在他们的实验中，所有被比较的（非 Transformer）基线都执行自回归或**迭代多步**（iterated multi-ste：IMS）预测[1,2,22,24]，已知对于长时序列预测（LTSF）问题，这些方法会遭受显著的误差累积效应。因此，在这项工作中，我们用**直接多步**（DMS）预测策略来挑战基于 Transformer 的长时序列预测解决方案，以验证其实际性能。

并非所有时间序列都是可预测的，更不用说长期预测了（例如对于混沌系统）。我们假设长期预测仅对那些具有相对清晰的趋势和周期性的时间序列是可行的。由于线性模型已经可以提取此类信息，我们引入了一组极其简单的模型，名为 LTSF-Linear，作为新的比较基准。LTSF-Linear 用一层线性模型对历史时间序列进行回归，以直接预测未来时间序列。我们在九个广泛使用的基准数据集上进行了广泛的实验，这些数据集涵盖了各种实际应用：交通、能源、经济、天气和疾病预测。令人惊讶的是，我们的结果表明，在所有情况下，LTSF-Linear 都优于现有的复杂基于 Transformer 的模型，并且通常优势很大（20%～50%）。此外，我们发现，与现有 Transformer 中的说法相反，它们中的大多数都无法从长序列中提取时间关系，即预测误差不会随着回溯窗口大小的增加而减少（有时甚至会增加）。最后，我们对现有的基于 Transformer 的 TSF 解决方案进行了各种消融研究，以研究其中各种设计元素的影响。

## 二、问题剖析与解决策略

### 2.1 Transformer-Based LTSF Solutions

基于Transformer的模型[26]在自然语言处理和计算机视觉领域的许多长期存在的人工智能任务中取得了无与伦比的性能，这得益于多头自注意力机制的有效性。这也引发了人们对基于Transformer的时间序列建模技术的大量研究兴趣[20, 27]。特别是，大量的研究工作致力于长期序列预测（LTSF）任务（例如[16, 18, 28, 30, 31]）。考虑到Transformer模型捕捉长距离依赖关系的能力，这些研究大多聚焦于较少被探索的长期预测问题。

当将原始的Transformer模型应用于LTSF问题时，它存在一些局限性，包括原始自注意力机制带来的二次时间/内存复杂度，以及自回归解码器设计导致的误差累积。Informer[30]解决了这些问题，并提出了一种新颖的Transformer架构，该架构降低了复杂度，并采用了直接多步预测（DMS）策略。后来，更多的Transformer变体将各种时间序列特征引入其模型中，以提高性能或效率[18, 28, 31]。我们总结了现有的基于Transformer的LTSF解决方案的设计要素如下（见图1）。

![20250316223631](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316223631.png)

#### 时间序列分解

在数据预处理方面，零均值归一化在时间序列预测（TSF）中很常见。此外，Autoformer[28]首次在每个神经模块之后应用季节性 - 趋势分解，这是时间序列分析中的一种标准方法，用于使原始数据更具可预测性[6, 13]。具体来说，他们在输入序列上使用移动平均核来提取时间序列的趋势 - 周期成分。原始序列与趋势成分之间的差异被视为季节性成分。在Autoformer的分解方案基础上，FEDformer[31]进一步提出了专家混合策略，将通过不同核大小的移动平均核提取的趋势成分进行混合。

#### 输入嵌入策略

Transformer架构中的自注意力层无法保留时间序列的位置信息。然而，局部位置信息，即时间序列的顺序，是很重要的。此外，全局时间信息，如分层时间戳（周、月、年）和通用时间戳（假期和事件），也包含有用信息[30]。为了增强时间序列输入的时间上下文，基于当前最优（SOTA）的Transformer方法的一个实用设计是将几种嵌入注入输入序列中，例如固定位置编码、通道投影嵌入和可学习的时间嵌入。此外，还引入了带有时间卷积层的时间嵌入[16]或可学习的时间戳[28]。

#### 自注意力机制

Transformer依赖自注意力机制来提取成对元素之间的语义依赖关系。为了降低原始Transformer的$O(L^{2})$时间和内存复杂度，近期的研究提出了两种提高效率的策略。一方面，LogTrans和Pyraformer明确地在自注意力机制中引入稀疏偏差。具体来说，LogTrans使用Logsparse掩码将计算复杂度降低到$O(LlogL)$，而Pyraformer采用金字塔注意力，以$O(L)$的时间和内存复杂度捕捉分层多尺度时间依赖关系。另一方面，Informer和FEDformer利用自注意力矩阵中的低秩性质。Informer提出了一种ProbSparse自注意力机制和自注意力蒸馏操作，将复杂度降低到$O(LlogL)$，而FEDformer设计了一个傅里叶增强模块和一个小波增强模块，并进行随机选择，以获得$O(L)$的复杂度。最后，Autoformer设计了一种序列级自相关机制来取代原始的自注意力层。

#### 解码器

原始的Transformer解码器以自回归的方式输出序列，这导致推理速度较慢，并且存在误差累积效应，特别是在长期预测中。Informer为DMS预测设计了一种生成式解码器。其他Transformer变体采用了类似的DMS策略。例如，Pyraformer使用一个全连接层，将时空轴连接起来作为解码器。Autoformer将来自趋势 - 周期成分的两个细化分解特征与堆叠的自相关机制得到的季节性成分特征相加，以获得最终预测。FEDformer也使用一种分解方案，并结合其提出的频率注意力模块来解码最终结果。

Transformer模型的前提是成对元素之间的语义相关性，而自注意力机制本身是排列不变的，其对时间关系进行建模的能力在很大程度上取决于与输入token相关的位置编码。考虑到时间序列中的原始数值数据（例如，股票价格或电力值），它们之间几乎没有逐点的语义相关性。在时间序列建模中，我们主要关注的是连续点集之间的时间关系，***并且这些元素的顺序而非成对关系起着最关键的作用***。虽然采用位置编码并使用token来嵌入子序列有助于保留一些顺序信息，但排列不变的自注意力机制的本质不可避免地会导致时间信息的丢失。基于上述观察，我们有兴趣重新审视基于Transformer的LTSF解决方案的有效性。

### 2.2 An Embarrassingly Simple Baseline

在现有的基于Transformer的长期序列预测（LTSF）解决方案（$T \gg 1$）的实验中，所有被比较的（非Transformer）基线模型都是迭代多步预测（IMS）技术，众所周知，这些技术存在显著的误差累积效应。我们假设，这些研究中性能的提升在很大程度上归功于其中使用的直接多步预测（DMS）策略。

为了验证这一假设，我们通过一个时间线性层提出了最简单的DMS模型，称为LTSF-Linear，作为比较的基线。LTSF-Linear的基本公式是通过加权求和操作，对历史时间序列进行回归以预测未来（如图2所示）。其数学表达式为$\hat{X}_i = WX_i$，其中$W \in \mathbb{R}^{T\times L}$是沿时间轴的线性层。$\hat{X}_i$和$X_i$分别是第$i$个变量的预测值和输入值。请注意，LTSF-Linear在不同变量之间共享权重，并且不对任何空间相关性进行建模。

LTSF-Linear是一组线性模型。原始线性模型（Vanilla Linear）是一个单层线性模型。为了处理不同领域（如金融、交通和能源领域）的时间序列，我们进一步引入了两种采用不同预处理方法的变体，分别称为DLinear和NLinear。

- 具体来说，DLinear是Autoformer和FEDformer中使用的分解方案与线性层的结合。它首先通过移动平均核对原始数据输入进行分解，得到趋势成分和剩余（季节性）成分。然后，对每个成分应用一个单层线性层，最后将两个特征相加得到最终预测值。通过明确处理趋势，当数据中存在明显趋势时，DLinear提高了原始线性模型的性能。
- 同时，为了在数据集存在分布偏移的情况下提升LTSF-Linear的性能，NLinear首先用序列的最后一个值减去输入值。然后，输入值通过一个线性层，在做出最终预测之前，再将减去的部分加回来。NLinear中的减法和加法操作是对输入序列的一种简单归一化。

## 三、实验验证与结果分析

### 3.1 Quantitative results

![20250316225626](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316225626.png)

### 3.2 Qualitative results

![20250316225722](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316225722.png)

如图3所示，我们绘制了基于Transformer的解决方案和LTSF-Linear在三个选定的时间序列数据集上的预测结果，这些数据集分别是电力数据集（序列1951，变量36）、汇率数据集（序列676，变量3）和ETTh2数据集（序列1241，变量2），它们具有不同的时间模式。当输入长度为96步，输出长度为336步时，基于Transformer的模型[28, 30, 31]在电力数据集和ETTh2数据集上未能捕捉到未来数据的规模和偏差。此外，对于如汇率这样的非周期性数据，它们几乎无法预测出合适的趋势。这些现象进一步表明，现有的基于Transformer的长期序列预测（LTSF）解决方案存在不足。

### 3.3 More Analyses on LTSF-Transformers

#### 现有长期序列预测Transformer模型（LTSF-Transformers）能否从更长的输入序列中有效提取时间关系？

回顾窗口的大小对预测准确性有很大影响，因为它决定了我们能从历史数据中学习到多少信息。一般来说，一个具有强大时间关系提取能力的高效时间序列预测（TSF）模型，应该能够在更大的回顾窗口下取得更好的结果。

为了研究输入回顾窗口大小的影响，我们针对长期预测（$T$ = 720），使用$L \in \{24, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720\}$进行了实验。图4展示了两个数据集上的均方误差（MSE）结果。与之前的研究[27, 30]的观察结果类似，当回顾窗口大小增加时，现有的基于Transformer的模型性能会恶化或保持稳定。相比之下，所有LTSF-Linear模型的性能都随着回顾窗口大小的增加而显著提升。因此，如果给定更长的序列，现有解决方案往往会过拟合时间噪声，而不是提取时间信息，并且输入长度96恰好适合大多数Transformer模型。

![20250316230902](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316230902.png)

此外，我们在附录中提供了更多的定量结果，并且我们的结论在几乎所有情况下都成立。

### 对于长期预测，我们能得出什么结论？

虽然回顾窗口中的时间动态对短期时间序列预测的准确性有显著影响，但我们假设长期预测仅取决于模型能否很好地捕捉趋势和周期性。也就是说，预测的时间跨度越远，回顾窗口本身的影响就越小。

![20250316231028](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316231028.png)

为了验证上述假设，在表3中，我们比较了来自两个不同回顾窗口的数据对未来720个时间步的预测准确性：(i) 原始输入$L$=96的设置（称为Close）；(ii) 在原始96个时间步之前的远距离输入$L$=96的设置（称为Far）。从实验结果来看，当前最优（SOTA）的Transformer模型的性能略有下降，这表明这些模型只能从相邻的时间序列中捕捉到相似的时间信息。***由于捕捉数据集的内在特征通常不需要大量参数，即一个参数就可以表示周期性。使用过多参数甚至会导致过拟合***，这在一定程度上解释了为什么LTSF-Linear的性能优于基于Transformer的方法。

### 自注意力机制对长期序列预测（LTSF）有效吗？

![20250316231128](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316231128.png)

我们验证了现有Transformer（如Informer）中的这些复杂设计是否必要。在表4中，我们逐步将Informer转换为线性模型。首先，我们用线性层替换每个自注意力层，称为Att.-Linear，因为自注意力层可以看作是权重动态变化的全连接层。此外，我们去掉Informer中的其他辅助设计（如前馈网络FFN），只保留嵌入层和线性层，称为Embed + Linear。最后，我们将模型简化为单个线性层。令人惊讶的是，Informer的性能随着逐步简化而提高，这表明至少对于现有的LTSF基准测试来说，自注意力机制和其他复杂模块是不必要的。

### 现有长期序列预测Transformer模型（LTSF-Transformers）能否很好地保留时间顺序？

![20250316231258](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316231258.png)

自注意力本质上是排列不变的，即与顺序无关。然而，在时间序列预测中，序列顺序通常起着关键作用。我们认为，即使有位置和时间嵌入，现有的基于Transformer的方法仍然会损失时间信息。在表5中，我们在嵌入操作之前打乱原始输入。我们提出了两种打乱策略：Shuf. 随机打乱整个输入序列；Half - Ex. 将输入序列的前半部分与后半部分交换。有趣的是，在汇率数据集上，与原始设置（Ori.）相比，即使输入序列被随机打乱，所有基于Transformer的方法的性能也没有波动。相反，LTSF-Linear的性能受到了显著影响。这表明具有不同位置和时间嵌入的LTSF-Transformers保留的时间关系非常有限，并且容易对有噪声的金融数据过拟合，而LTSF-Linear可以自然地对顺序进行建模，并且用较少的参数避免过拟合。

对于ETTh1数据集，FEDformer和Autoformer在其模型中引入了***时间序列归纳偏置***，使得当数据集比汇率数据集具有更清晰的时间模式（如周期性）时，它们能够提取一定的时间信息。因此，在Shuf. 设置下，这两种Transformer模型的平均性能下降了73.28%和56.91%，因为此时失去了整个顺序信息。此外，由于Informer没有这种时间归纳偏置，在Shuf. 和Half - Ex. 设置下受影响较小。总体而言，在所有情况下，LTSF-Linear的平均性能下降幅度都大于基于Transformer的方法，这表明现有的Transformer模型不能很好地保留时间顺序。

### 不同的嵌入策略效果如何？

![20250316231524](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316231524.png)

我们研究了基于Transformer的方法中使用的位置和时间戳嵌入的作用。在表6中，没有位置嵌入（wo/Pos.）时，Informer的预测误差大幅增加。没有时间戳嵌入（wo/Temp.）时，随着预测长度的增加，Informer的性能会逐渐下降。由于Informer对每个token使用单个时间步，因此有必要在token中引入时间信息。

FEDformer和Autoformer不是对每个token使用单个时间步，而是输入一个时间戳序列来嵌入时间信息。因此，在没有固定位置嵌入的情况下，它们也能取得相当甚至更好的性能。然而，没有时间戳嵌入时，Autoformer的性能会迅速下降，因为丢失了全局时间信息。相比之下，由于FEDformer中提出的频率增强模块引入了时间归纳偏置，在移除任何位置/时间戳嵌入时，其性能受到的影响较小。

### 训练数据量是现有长期序列预测Transformer模型（LTSF-Transformers）的限制因素吗？

有人可能会认为，基于Transformer的解决方案性能不佳是由于基准数据集规模较小。与计算机视觉或自然语言处理任务不同，时间序列预测（TSF）是在收集的时间序列上进行的，很难扩大训练数据量。事实上，训练数据的规模确实会对模型性能产生重大影响。

![20250316231706](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316231706.png)

因此，我们在交通数据集上进行了实验，比较了在完整数据集（17,544*0.7小时）上训练的模型（称为Ori.）和在缩短后的数据集（8,760小时，即1年）上训练的模型（称为Short）的性能。出乎意料的是，表7显示，在大多数情况下，减少训练数据后的预测误差更低。这可能是因为全年的数据比更长但不完整的数据保持了更清晰的时间特征。虽然我们不能得出应该使用更少数据进行训练的结论，但这表明训练数据规模并不是Autoformer和FEDformer性能不佳的限制因素。

### 效率真的是首要关注点吗？

![20250316232042](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250316232042.png)

现有的长期序列预测Transformer模型（LTSF - Transformers）声称，原始Transformer的$O(L^{2})$复杂度对于长期序列预测（LTSF）问题来说是难以承受的。尽管它们证明能够将理论上的时间和内存复杂度从$O(L^{2})$降低到$O(L)$，但尚不清楚：1）设备上的实际推理时间和内存成本是否得到改善；2）对于如今的GPU（例如这里的英伟达泰坦XP）而言，内存问题是否无法接受且紧迫。在表8中，我们比较了5次运行的平均实际效率。有趣的是，与原始Transformer（具有相同的直接多步预测（DMS）解码器）相比，大多数Transformer变体在实际应用中会导致相似甚至更差的推理时间和参数数量。这些后续模型引入了更多额外的设计元素，从而增加了实际成本。此外，即使输出长度$L = 720$，原始Transformer的内存成本在实际中也是可接受的，这削弱了开发内存高效的Transformer模型的重要性，至少对于现有的基准测试是如此。
