# A Comprehensive Survey of Deep Learning for Multivariate Time Series Forecasting: A Channel Strategy Perspective

>领域：时间序列 Survey  
>发表在：Arxiv  
>文章链接：[A Comprehensive Survey of Deep Learning for Multivariate Time Series Forecasting: A Channel Strategy Perspective](https://arxiv.org/abs/2502.10721)  
![20250314095627](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250314095627.png)  

## 1 Taxonomy of Channel Strategies in MTSF

### 1.1 Strategy Perspective

![20250314144445](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250314144445.png)

#### Channel Independence (CI)

CI 策略独立处理每个通道，不考虑通道之间的任何潜在交互或相关性。每个通道都被作为单独的输入进行处理，不使用任何共享信息或依赖关系。具有代表性的方法 PatchTST（Nie 等人，2023）采用了 CI，并在多变量时间序列预测（MTSF）中表现出出色的性能。这种设计显著***降低了模型复杂性，能够实现更快的推理，同时降低了由通道之间的噪声或虚假相关性引起的过拟合风险***。此外，CI 策略提供了灵活性，***因为添加新通道不需要对模型架构进行更改，使其能够无缝适应不断发展的数据集***。这些优势使得 CI 策略在最近的研究中越来越受欢迎，有助于提高预测性能（Lin 等人，2024；Zeng 等人，2023）。

#### Channel Dependence (CD)

CD 策略假定多元时间序列中的所有通道本质上都是相关且相互依赖的，在预测过程中将它们视为一个统一的实体。根据学习通道间交互的阶段，现有的 CD 方法可分为两类：  
***嵌入融合***：这些模型在获取时间序列嵌入表示时融合来自不同通道的数据。例如，Informer [Zhou 等人，2021]、Autoformer [Wu 等人，2021]和 TimesNet [Wu 等人，2023a]使用一维或二维卷积来提取时间表示。在卷积操作中，每个卷积核首先在每个输入通道内进行滑动卷积以获得相应的特征图。然后对所有通道的这些特征图进行加权和组合，以捕获通道之间的依赖关系。  
***显式相关性***：这些模型通常设计专门的模块来显式地对通道相关性进行建模，基于获取的时间序列嵌入表示促进更结构化的通道建模。具有代表性的算法包括 iTransformer [Liu 等人，2024b]和 TSMixer [Ekambaram 等人，2023]。iTransformer 在通道之间采用自注意力模块，将独立的时间序列视为token，并使用自注意力机制捕获多元相关性。相比之下，TSMixer 在通道之间使用 MLP 模块来捕获通道之间的复杂相关性，这些相关性由通过全连接层提取的多级特征表示。

#### Channel Partiality (CP)

通道偏倚策略在通道独立（CI）和通道依赖（CD）之间取得平衡，使每个通道在与其他相关通道交互的同时，还能保持一定程度的独立性。这种方法强调一种混合状态，即通道进行选择性交互，并呈现出部分相关性。根据每个通道的相关通道数量是固定的还是动态的，现有的通道偏倚方法可分为两类：

- **固定部分通道**：这些模型为每个通道固定相关通道的数量，这意味着相关通道的集合随时间保持不变。例如，在MTGNN（多任务图神经网络，[Wu等人，2020]）中，通道关系被建模为K-正则图，其中每个通道使用通道依赖策略与K个其他通道进行交互，以对相互依赖关系进行建模，而其余通道则通过通道独立策略进行交互。

类似地，在MCformer [Han等人，2024b] 中，每个通道仅与K个其他通道进行交互，与其余通道保持通道独立策略，以确保计算效率并防止过拟合。

- **动态部分通道**：这些模型允许每个通道的相关通道数量是动态变化的，会随时间改变，从而为适应不同场景提供更大的灵活性。例如，DUET [Qiu等人，2025] 通过度量学习计算通道相似度，然后对结果进行稀疏化处理。这会生成一个掩码矩阵，该矩阵被集成到融合模块的注意力机制中，确保每个通道仅与相关通道交互，减少来自噪声通道的干扰。另一个例子是CCM [Chen等人，2024]，它根据通道的内在相似度对通道进行动态聚类。为了有效捕捉这些聚类中的潜在时间序列模式，CCM利用了一种聚类感知前馈机制，能够针对每个单独的聚类进行定制化的管理和处理。

### 1.2 Mechanism Perspective

#### Transformer-based

![20250314145704](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250314145704.png)

##### Naive Attention

这些方法都采用了跨维度（CD）策略。将时间序列片段（补丁）或每个通道的整个序列视为单独的token，并直接应用注意力机制对通道相关性进行建模。例如，CARD [Wang 等人，2024b]和 iTransformer [Liu 等人，2024b]分别将每个通道的补丁和序列表示为独立的token，并使用注意力机制明确捕获通道相关性。

##### Router Attention

当通道数量较大时，通道注意力的计算复杂度达到很高水平，导致计算成本高昂。为了解决这个问题，一些方法提出了优化策略，以减轻由 CD 策略引起的计算复杂性。例如，Crossformer [Zhang 和 Yan，2022]为朴素注意力引入了一种路由器机制，它使用少量固定数量的“路由器”来收集来自所有通道的信息并重新分配。这将复杂度降低到一定程度。这种机制有效地平衡了通道相关性建模和计算效率。

##### Frequency Attention

一些 CD 方法表明，频域信息在捕获通道间依赖关系方面比时域信息更有效。例如，FECAM [Jiang 等人，2023]将时间序列数据转换到频域，然后在该域中使用朴素注意力对通道间关系进行建模。

##### Mask Attention

在朴素注意力中，每个通道与所有通道计算注意力分数，这可能会受到不相关通道的负面影响。为了减轻这种影响，掩码注意力通过构建 CP 策略提供了一种避免不相关噪声的方法。例如，DUET [Qiu 等人，2025]为朴素注意力生成掩码矩阵，允许每个通道专注于那些对下游预测任务有益的通道，同时减轻噪声或不相关通道的影响。这种方法明确约束了注意力计算，提高了通道相关性建模的准确性。

#### MLP-based

![20250314151104](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250314151104.png)
多层感知器（MLP）作为骨干网络，根据universal approximation theore，具备强大的特征学习能力。现有的基于MLP的模型以通道依赖（CD）的方式使用MLP混合，通过全连接层提取的多级特征来表示通道之间的复杂相关性，以此捕捉通道间的复杂关联（见图3）。从通道策略的角度来看，诸如TSMixer（[Ekambaram等人，2023]）和Tiny-TTM（[Ekambaram等人，2024]）等属于MLP混合类别的模型，采用这种方法来高效捕捉所有通道之间的相关性，以较低的计算成本实现了出色的性能，且都属于通道依赖（CD）策略。

#### CNN-based

![20250314151109](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250314151109.png)

卷积神经网络（CNN）是一种深度学习模型，利用卷积层从数据中提取局部特征。如图 3 所示，所探索的基于 CNN 的方法可以大致分为以下几类：

I）合并：许多模型，如 Informer[Zhou 等人，2021]、Autoformer[Wu 等人，2021]和 FEDformer[Zhou 等人，2022]，在初始特征提取层中使用一维卷积并沿时间维度进行滑动操作。这些模型将不同的通道视为卷积的不同输入，其特征在卷积过程中进行加权和合并，从而实现通道间的交互。尽管 TimesNet[Wu 等人，2023a]采用二维卷积，但它将时间维度折叠成二维格式，可变通道仍然作为独立输入，通过卷积进行加权合并。这些模型都属于 CD 策略。

II）卷积：鉴于通道之间的空间依赖性较小，ModerTCN[Luo 和 Wang，2024]直接应用卷积操作以促进局部范围内通道之间的信息交互。在同一卷积窗口内，通道通过卷积核以 CD 方式相互交互，而不能分配到同一窗口的通道彼此保持独立。这为 CP 建模提供了一种有效的方法。

#### GNN-based

![20250314151256](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250314151256.png)

通过沿时间维度将时间序列划分为不同的窗口，窗口内的每个通道被视为一个节点，通道之间的相关性视为边，多元时间序列就可以转换为基于图的数据。基于GNN的方法可分为密集图和稀疏图两类。在密集图中，每个节点通常几乎与所有其他节点相连，边往往表示相关影响的强度。像GTS（[Shang等人，2021]）和FourierGNN（[Yi等人，2023]）等基于密集图的方法，通常遵循通道依赖（CD）策略。相比之下，稀疏图只保留必要的边，大多数节点保持独立。例如，MTGNN（[Wu等人，2020]）为每个节点保留K条边，构建了一个稀疏的K-正则图。与此不同的是，MTSF - DG（[Zhao等人，2023]）根据预设阈值过滤掉低概率的边，对邻接矩阵进行稀疏化处理。基于稀疏图的方法属于通道偏倚（CP）策略。

所构建图的稀疏性决定了该方法遵循的是CD策略还是CP策略。此外，基于GNN的模型在实施CD或CP策略时，通常依赖于它们所构建的图的类型。如图4所示，我们对图的类型分类如下：

1. **简单图**：简单图是最基础的图模型，每对节点之间最多有一条边。有效的信息传递需要一个定义明确的图结构。研究人员利用通道相似性度量（如MTGNN、MSGNet（[Cai等人，2024]）、CrossGNN（[Huang等人，2023a]））和数据相似性度量（如GTS、WaveForM（[Yang等人，2023]））来学习多元通道之间的相关图结构。他们利用时域信息（MTGNN、MSGNet、CrossGNN、GTS）或频域信息（WaveForM）作为节点学习特征。在简单图内应用基于图卷积的信息传递，以促进通道间依赖信息的传播。
2. **时空图**：与简单图不同，时空图将不同时间步的多个通道整合到一个图中，进一步考虑不同时间步通道之间的关系。这种方法使GNN能够同时对时间和通道依赖关系进行建模，有效解决时间模块和GNN之间潜在的兼容性问题。基于时空图的方法的主要挑战在于解决图构建和信息传递阶段的效率问题。例如，FourierGNN使用全连接图构建，并采用Fourier域卷积算子，实现了O(Nlog(N))的时间复杂度。类似地，FC - STGNN（[Wang等人，2024c]）采用相同的图构建方法，并使用移动池化卷积来达到相同的时间复杂度。
3. **超图**：超图是图的扩展，超边可以连接多个顶点，能够对高阶群组交互进行建模。基于超图的模型假设通道之间的交互不是两两的，而是涉及多个通道之间基于群组的交互。因此，基于超图的模型本质上适合构建CP策略。ReMo（[Wu等人，2023b]）和Ada - MSHyper分别构建了多视图和多尺度超图，并在这些超图上设计了信息传递机制，以实现群组级别的信息传播。值得注意的是，它们使用不同的MLP或聚类约束来促进群组间的异质性表达。
4. **时间图**：在现实世界中，时间序列数据的相关性通常会随时间变化，形成动态关系图。MTSF - DG和TPGNN（[Liu等人，2022]）分别使用动态图和多项式图来对这些相关性的变化模式进行建模。CP模型MTSF - DG结合了历史和未来的关系图，利用记忆网络和逻辑符号学习来捕捉历史相关性对未来相关性的影响。CD模型TPGNN将相关矩阵表示为具有时变系数的矩阵多项式，以学习相关性的演变模式。

#### Other

除了上述机制之外，一些模型还提出了替代方法。例如：I）CD 模型 SOFTS [Han 等人，2024a]引入了 STAR 模块，该模块利用集中式结构首先使用多层感知机（MLP）从所有通道聚合信息，然后将聚合信息分发到每个通道。这种交互不仅降低了通道间交互的复杂性，还最大限度地减少了对单个通道质量的依赖。II）CP 模型 LIFT [Zhao 和 Shen，2024]提出了一种新颖的插件，适用于所有特定于多变量时间序列预测（MTSF）的模型，该插件在每个时间步有效地估计领先指标及其领先步数。这种方法使滞后通道能够利用来自预定义的领先指标集的高级信息。III）C-LoRA [Nie 等人，2024]引入了一种通道感知低秩自适应（CLoRA）插件，该插件适用于所有特定于多变量时间序列预测（MTSF）的模型。它首先使用低秩分解适配器对每个通道进行参数化，以实现个性化处理。然后，根据序列信息对专门的通道自适应进行调整，以形成身份感知嵌入。此外，通过集成全局共享的 CD 模型来捕获跨通道关系依赖。

### 1.3 Characteristics Perspective

![20250315191524](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250315191524.png)

#### Asymmetry

不对称性是指多变量时间序列中各通道之间的不平等关系，即通道间的相互影响程度并不相同。基于Transformer和多层感知器（MLP）的方法，由于其计算过程的特定性质，本质上就具有不对称性，这使得它们能够有效地捕捉到非对称相关性。另一方面，基于图神经网络（GNN）的方法通过非对称距离度量来构建有向加权图，使得交互边在不同的传输方向上可以具有不同的权重，如在MTGNN（Wu等人，2020年）、MSGnet（Cai等人，2024年）等模型中所展示的那样。

#### Lagginess

滞后性是指某个通道的当前状态不仅取决于其他通道的当前状态，还可能受到其他通道过去状态的影响。基于滞后性特征，VCformer（Yang 等人，2024）在计算注意力矩阵时纳入了通道之间多步延迟的联合影响。相比之下，FourierGNN（Yi 等人，2023）和 FC-STGNN（Wang 等人，2024c）使用时空全连接图在不同通道和时间步的表示之间直接进行消息传递。另一方面，LIFT（Zhao 和 Shen，2024）将先验知识与神经网络预测相结合来估计滞后步长。

#### Polarity

极性是指通道间相互作用中正负相关性的区别。在建模过程中，区分这两种类型的相互作用非常重要，以避免混淆。CrossGNN（Huang 等人，2023b）采用符号图方法，将相关性分为正、负和中性关系。在消息传递过程中，它整合了正负信息交换，从而更有效地捕捉相关性的异质性。

#### Group-wise

“组向性”是指一种现象，其中通道之间的相关性呈现出分组结构，其特点是同一组内的相关性强，不同组之间的相关性弱，并且不同组之间的相关依赖性各不相同。CCM（Chen 等人，2024）和 DUET（Qiu 等人，2025）使用聚类技术对通道进行分组以进行交互，而 ReMo（Wu 等人，2023b）和 Ada-MSHyper（Shang 等人，2024）通过超边建立组内消息传递。此外，CCM 和 ReMo 为不同组内的特征提取应用不同的多层感知机，而 Ada-MSHyper 根据损失函数约束超边。这些不同的方法有助于表达不同组之间的差异。

#### Dynamism

多变量时间序列中各通道之间的相关性在不同时间步长下表现出不同的特征，呈现出一种整体的动态变化。首先，基于多层感知器（MLP）的方法（如TimeMixer [Wang等人，2024a]、TTM [Ekambaram等人，2024]），其权重在各个时间步长上保持不变，无法捕捉动态性。通常使用Transformer来考虑通道相关性的方法会采用序列token（series tokens）或补丁token（patch tokens）。基于序列token的方法，如iTransformer [Liu等人，2024b]和DUET [Qiu等人，2025]，无法捕捉动态性。然而，基于补丁token的方法，如Cross - former [Zhang和Yan，2022]，在不同的时间补丁上分配不同的注意力分数，从而能够对动态性进行建模。在图神经网络（GNNs）中，只有图结构随时间变化的方法才能捕捉动态性，例如MSGNet [Cai等人，2024]，它在每个时间步计算图结构。但是，上述对动态性进行建模的方法仅考虑了不同时间步长下不同的通道关系。相比之下，MSTF - DG [Zhao等人，2023]、TPGNN [Liu等人，2022]和ESG [Ye等人，2022]提出，不同时间步长之间的通道关系存在直接联系。例如，MSTF - DG利用先前的通道关系来直接推断当前的通道关系。

#### Muti-scale

“多尺度”是指通道之间的相关性在不同时间尺度（如小时、分钟或秒）下表现出不同的行为现象。MSGNet（Cai 等人，2024 年）和 Ada-MSHyper（Shang 等人，2024 年）在不同尺度上建立不同的图结构，以描述不同层次相关性的变化，并通过不同程度的交互实现不同尺度相关性信息的融合。考虑相关性的多尺度异质性有助于模型更好地理解时间序列数据的多尺度特征，从而生成更准确的预测。

## Comparison within the Taxonomy

![20250315211031](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250315211031.png)

在本节中，我们从多个维度比较CI、CD和CP的优缺点，详见表2。

### 效率

效率衡量的是模型在运行过程中消耗的资源量，如时间和内存。CI是最有效的策略，因为它独立处理每个通道，无需对通道间关系进行建模。这使得它的计算复杂度最低，并且对于大型数据集具有出色的可扩展性。CD是效率最低的策略，因为它需要对所有通道间的依赖关系进行建模。随着通道数量的增加，其计算复杂度会急剧上升，导致可扩展性较差。CP策略通过动态捕捉通道间的相互作用来实现平衡，它允许每个通道仅关注与自身最相关的通道。由于其动态机制限制了建模范围，CP的效率仍然高于CD。

### Robustness

Robustness是指模型在面对噪声、数据变化或干扰时保持稳定性和有效性的能力。CI对噪声具有一定程度的稳健性，因为它独立处理每个通道，避免了通道间的干扰。CD对于强相关的通道具有较高的稳健性，但对噪声非常敏感。虚假相关性会显著降低其性能，使其成为最不稳健的策略。CP通过捕捉灵活且动态的关系展现出高度的稳健性，使其在处理噪声和数据分布变化方面非常有效。

### 泛化性

泛化性是指模型通过利用训练数据之外的模式和关系，在未见过的数据或不同数据集上良好运行的能力。CI的泛化性最弱，因为它无法利用通道相关性，这对于多变量时间序列任务来说是一个关键缺陷。当通道相关性一致且显著时，CD表现出较强的泛化性。然而，当相关性较弱或在不同数据集之间差异很大时，其性能会下降。CP通过处理重叠且动态的通道相关性表现出最强的泛化性。它能很好地适应各种数据集，尤其是在复杂的现实场景中。

### 容量

容量是指模型捕捉和表示数据中复杂关系和依赖的能力。CI的容量最低，因为它完全忽略了通道间的关系，只能对单个通道的动态变化进行建模。CD的容量最高，因为它同时对所有通道间的关系进行建模，能够捕捉复杂的全局依赖。CP策略提供了一种平衡的方法，具有适度的容量。它有选择地对相互作用进行建模，使每个通道仅关注与自身最相关的通道。

### 易实现性

易实现性是指将模型付诸实践的直接程度或复杂程度，这需要考虑所需的组件和设计。CI是最容易实现的策略，因为其结构简单，无需对通道间关系进行建模。CD的实现更为复杂，因为它需要设计模块来捕捉通道间的依赖关系。CP是最难实现的策略，因为它需要一种动态且灵活的机制来对通道间的依赖关系进行建模。通常，这涉及到使用注意力机制或基于图的方法，从而增加了实现的难度。

## 未来的研究方向

### Future Horizon内的通道相关性

目前，很少有模型研究Future Horizon内的相关关系。Future Horizon内的相关性直接影响预测结果的质量。尽管一些方法，如TPGNN（Liu等人，2022）和MTSF - DG（Zhao等人，2023），使用基于时间图的方法来预测未来时间范围内的通道相关性，但相应地，它们侧重于短期预测，并且由于性能限制，难以扩展到长期预测。

#### 其他相关特征

现有研究方法已经探索和分析了通道相关性的六个特征。然而，在现实场景中，相关性还包含其他特征，例如：

- **多组件性**：DLinear（Zeng等人，2023）和AutoFormer（Wu等人，2021）已经证明，将时间序列分解为趋势和季节性等多个组件，对多变量时间序列预测（MTSF）有重大贡献。未来的研究可以探索如何分别对每个组件内的通道相关性进行建模，以及如何整合多个组件之间的通道相关性。
- **多频率性**：相关性可能在时间序列数据的不同频率组件中表现不同，等等。对这些特征的进一步探索可以帮助模型更好地理解和利用通道之间的相关性，最终提高其预测和推断能力。

#### 5.3 通道相关性的多模态研究

可以引入多种模态，以更全面地对通道之间的相关性进行建模。与单时间序列模态相比，多模态数据可以提供更丰富的信息来源，如文本、图像或其他传感器数据，这可以弥补时间序列数据中可能存在的不足。通过从多模态数据中提取特征，可以捕捉不同模态下通道的独特特征。随后，可以使用跨模态关系建模机制，如跨模态注意力机制或图神经网络（GNN），来揭示通道之间的动态依赖关系。此外，为了进一步加强对通道相关性的建模，可以设计一种自适应融合机制，根据不同模态之间的相关性动态调整交互权重。

#### 5.4 基础模型的通道策略

多变量时间序列基础模型主要有两种方法：基于大语言模型（LLM）的模型和时间序列预训练模型。基于LLM的模型在语言模态中缺乏通道维度，通常采用CI策略（Jin等人，2024；Chang等人，2023）。由于时间序列数据中通道数量具有高度异质性，大多数时间序列预训练模型，如Timer（Liu等人，2024c）和Chronos（Ansari等人，2024），使用CI策略以确保稳健的预测，同时避免复杂的通道相关性。相比之下，像MOIRIA（Woo等人，2024）和UniTS（Gao等人，2024）这样的模型在预训练期间纳入了通道相关性。MOIRIA将所有通道展平，使用位置嵌入来区分它们，通过自注意力捕捉时间和通道关系，而UniTS则通过通道维度中的自注意力直接捕捉通道相关性。然而，时间序列预训练模型仅考虑CD策略来捕捉通道相关性，没有充分考虑不同预训练数据集中复杂多样的通道相关性，而CP策略可能会取得更好的性能。此外，基于LLM的模型中也缺乏考虑将通道相关性与多模态数据相结合的研究。现有方法相对基础，在基础模型中改进通道策略仍有很大的提升空间 。
