# Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis

>领域：时空、时序Benchmark  
>发表在：TKDE 2024  
>名字： BasicTS  
>文章链接：[Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis](https://arxiv.org/pdf/2310.06119)  
>代码仓库：[https://github.com/GestaltCogTeam/BasicTS](https://github.com/GestaltCogTeam/BasicTS)  

## Introduction

近年来，多变量时间序列（MTS）预测解决方案主要基于深度学习 [7]、[9]、[10]、[6]、[11]、[12]。这些解决方案通常解决两个突出且更具体的问题，即长期时间序列预测（LTSF）和时空预测（STF），其中对数据中的时间和空间模式进行建模至关重要。

- LTSF 解决方案关注长期预测，通常采用像 Transformer 这样的高级神经网络 [13] 来建模长期时间依赖性。值得注意的解决方案包括高效 Transformer [14]、[7]、[15]、序列级相关性 [9]、基于频率的解决方案 [10] 以及利用分块时间序列的 Transformer [16]、[8]。
- 相比之下，STF 解决方案旨在通过有效建模空间相关性来改进预测。流行的方法是将图卷积网络（GCN）[17] 与不同的序列模型 [18]、[19] 结合，形成时空图神经网络（STGNN）。示例包括将 GCN 与循环神经网络（RNN）[6]、卷积神经网络（CNN）[11] 以及注意力机制 [20]、[21] 相结合。

虽然新解决方案的提议包括实验研究，但这些研究有时不可比或看似不一致。这导致了在采取何种方向上的不确定性，并阻碍了朝着更好解决方案的进展。

- 作为当前情况的一个例子，一些研究 [22]、[23]、[24]、[25] 报告了关键基线 DCRNN [6] 和 GWNet [11] 的性能不佳，比我们重现的性能低多达 33%。
- 长时序列预测解决方案的提议 [7]、[9]、[10]、[8] 通常仅使用基于归一化时间序列的指标（如 MAE 和 MSE）报告评估结果，使得预测误差看起来非常低。另一种方法是在重新归一化的数据上进行评估，并评估更多不受数据范围的影响的，如平均绝对百分比误差（MAPE）和加权绝对百分比误差（WAPE）这样的指标。诸如此类的问题使研究人员无法判断不同解决方案的优缺点。

此外，一些研究在选择追求长期时空序列预测（LTSF）和短期时空序列预测（STF）更好解决方案的技术方向时，呈现出看似矛盾的发现。

- 关于时间方面，（i）高级神经网络的有效性一直存在争议 [7]、[26]、[16]、[27]。一项研究 [26] 发现，采用简单线性层的 LTSF-Linear 显著优于基于 Transformer 的模型 [7]、[9]、[10]、[15]，并且该研究得出结论，基于 Transformer 的架构并不像先前声称的那样有效。然而，后续的研究 [16]、[28]、[27] 发现高级神经网络优于 LTSF-Linear。我们发现这些方法之间的模型大小差异使得难以确定它们的相对有效性。
- 关于空间方面，（ii）图卷积网络（GCN）的必要性受到质疑 [29]、[30]。虽然时空图神经网络（STGNN）带来了显著的改进，但许多最近的研究强调了 STGNN 的低效性，并探索了对时间序列之间的依赖关系进行建模的替代方法，例如归一化 [30]、[31]。这些非 GCN 方法的成功表明需要更深入地理解空间依赖性，并深入了解这些替代方法何时有效。

为了缓解上述问题并提供对所取得进展的洞察，我们对多变量时间序列（MTS）预测数据集和模型进行了全面的分析和比较。首先，由于我们认为为 MTS 预测提供一个公平、全面且可重复的基准可以缓解当前的状况并推动进步，因此我们引入了 BasicTS+，这是一个用于研究和比较 MTS 预测解决方案的基准。BasicTS + 建立了统一的训练流程和合理的评估设置。前者解决了先前研究中由于独特的数据和实验设置而导致的性能不一致问题，而后者能够更直观地评估预测误差。总体而言，BasicTS + 有助于对超过 45 种流行的 MTS 进行公平、全面且可重复的评估。

其次，我们通过研究多变量时间序列（MTS）数据集之间的异质性影响来解决选择合适技术方法的问题。我们使用***异质性***来指代在不同的 MTS 数据集中观察到的完全不同的模式。

- 在时间方面，我们将数据集分为具有稳定模式、显著分布漂移和模式不清晰的数据集。
- 在空间方面，我们发现空间样本不可区分性是一个关键概念，并将数据集分为具有显著空间样本不可区分性和不具有显著空间样本不可区分性的数据集。

实验研究表明，先前的结论仅对某些类型的数据有效。例如，基本神经网络 [26] 仅在没有稳定时间模式的数据集上优于高级神经网络 [7]、[9]、[10]，而用于建模空间依赖关系的方法，如基于图卷积网络（GCN）的方法，仅在某些数据集上有效。具有显著的空间样本不可区分性。我们发现，盲目采用先前研究的结论可能会导致研究人员做出错误的推断。

此外，通过在异构数据集上使用 BasicTS+，我们对流行的解决方案进行了详尽的分析和比较。首先，我们讨论了如何为给定的多变量时间序列（MTS）数据集设计或选择 MTS 预测解决方案，以及如何为给定的 MTS 预测解决方案选择合适的数据集进行评估。随后，我们在综合数据集上展示了流行解决方案的性能和效率的详细实验结果，揭示了所取得的进展。这些结果和讨论的目的是加速进展，并帮助研究人员得出更可靠的结论。此外，我们强调了值得更多关注的方向。总之，我们做出了以下主要贡献：

- 我们提出了 BasicTS+，这是第一个专门为多变量时间序列预测解决方案（特别是短期时间序列预测和长期时间序列预测解决方案）的公平比较而设计的基准。BasicTS+ 便于在 20 个数据集上对 45 多个流行模型进行评估，以解决看似不一致的性能结果。
- 我们将 MTS 数据集的异质性确定为一个关键挑战，并根据时间和空间特征对数据集进行分类。我们发现忽略异质性是选择技术方向困难的一个原因，并且以前的结论仅适用于某些类型的数据
- 我们使用 BasicTS+ 和丰富的异构数据集对流行模型进行了广泛的分析和比较。这些发现为已经取得的进展提供了有价值的见解，帮助研究人员选择合适的解决方案或数据集，并得出更可靠的结论。

本文的结构如下。第二部分对长时间序列预测（LTSF）、短期时间序列预测（STF）和多变量时间序列（MTS）预测基准测试的相关工作进行了讨论。第三部分涵盖了预备知识和基本定义。第四部分介绍了 BasicTS + 基准。第五部分深入探讨了多变量时间序列数据集之间的异质性，并为解释看似矛盾的发现提供了假设。第六部分报告了 BasicTS + 在流行模型中的应用，并提供了新的见解。第七部分对本文进行了总结。

## Related Work

### 长时间序列预测 LTSF

为了实现准确的长期时间序列预测 [32]，研究***集中在捕捉多变量时间序列数据中的时间模式***，并提出了有效纳入***更长期历史信息***的方法。例如，在电力系统中预测未来几个月甚至几年的电力需求是一个典型的应用场景。

早期研究通常提出传统统计方法（例如，ARIMA [33] 和 ETS [34]）或机器学习方法（例如，GBRT [35] 和 SVR [36]）。这些方法通常难以很好地处理高度非线性，并且它们通常严重依赖与平稳性相关的假设 [3]。随着深度学习的出现 [37]、[38]，研究已经采用更强大和先进的神经架构进行时间序列建模，例如 TCN [19]、LSTM [39] 和 Transformer [13]。在这些方法中，基于 Transformer 的模型越来越受到关注。Informer [7] 提出了一种 ProbSparse 自注意力机制和蒸馏操作，以解决 Transformer 的二次复杂性问题，从而带来显著的性能提升，并被认为是长时序预测（LTSF）的一个里程碑（AAAI 2021 最佳论文）。随后，Autoformer [9] 具有高效的自相关机制，可在序列级别发现和聚合信息，而 FEDformer [10] 提出了一种在频率上具有低秩近似的注意力机制和混合专家来控制分布偏移。此外，Pyraformer [15] 设计了金字塔注意力，以低复杂度有效地描述短期和长期时间依赖性。总体而言，Transformer 架构被广泛认为是多变量时间序列预测（MTS forecasting）最有效和最有前途的方法之一。

然而，最近的一项研究提出了 LTSF-Linear [26]，并对 Transformer 架构的有效性提出了质疑。LTSF-Linear 采用了一个简单的线性层，并且性能优于所有早期的模型。它仔细研究了 Transformer 的每个关键组件，并得出结论，它们在时间序列预测中是无效的。这一结论随后受到了研究 [16]、[27]、[28] 的挑战，这些研究采用先进的神经网络来超越 LTSF-Linear。然而，考虑到模型大小的巨大差异和预测性能的微小差异，充分理解先进模型的有效性仍然具有挑战性。此外，需要更多的探索来理解为什么一个简单的线性模型可以实现最先进的性能。

### 多变量时间序列预测 MTS

与长期时空预测（LTSF）不同，时空预测不仅必须应对时间序列中的时间动态，还必须应对时间序列之间的依赖关系。一个典型的例子是在交通管理中，预测未来状况需要来自多个交通传感器的数据，这清楚地凸显了这些传感器之间的空间依赖性。因此，大量的研究致力于有效地捕捉和建模这些时空模式。

早期的深度学习方法通常采用卷积神经网络（CNNs）来处理空间信息，并结合卷积神经网络和循环神经网络（RNNs）[40]、[41]、[2]。然而，由于时间序列之间的关系通常是***非欧几里得***的，基于网格的卷积神经网络可能不是处理空间依赖关系的最佳选择。随着图卷积网络（GCNs）[42]、[17] 的发展，时空图神经网络（STGNNs）[6]、[12] 越来越受到关注。时空图神经网络利用图卷积网络基于预定义的先验图对空间依赖关系进行建模，并进一步将它们与序列模型 [19]、[18]、[13] 结合起来。

诸如 DCRNN [6]、ST-MetaNet [43] 和 DGCRN [44] 等模型将图卷积网络（GCN）与循环神经网络（RNN）[18] 及其变体相结合，然后按照序列到序列（seq2seq）[39] 架构逐步进行预测。Graph WaveNet [11]、STGCN [12] 和 Auto-DSTSGN [45] 将 GCN 与门控时间卷积网络（TCN）及其变体相结合，以促进并行计算。此外，注意力机制在时空图神经网络（STGNN）中得到广泛应用，例如 GMAN [20]、ASTGNN [46]。另外，神经架构搜索解决方案 [45]、[47] 也受到了广泛关注。然而，许多近期研究认为，在许多情况下，预定义的先验图可能存在偏差、错误甚至不可用。因此，他们提出共同学习图结构（即潜在图）并优化 STGNN，例如 AGCRN [48]、MTGNN [49]、StemGNN [23]、GTS [50]、DFDGCN [51] 和 STEP [52]。

然而，由于图卷积操作，先前的基于图的时空图神经网络和潜在图的时空图神经网络通常具有从  $O(N^{2} L)$ 到 $O(N^{2} L^{2})$ 的复杂度，其中 $N$ 是时间序列的数量，$L$ 是时间序列的长度。因此，最近的研究[53]、[54]对时空图神经网络[31]、[29]、[55]、[56]的必要性提出了质疑，并探索了替代技术[30]、[31]、[57]。例如，STNorm[31]引入了时空归一化，STID[30]实现了一种简单而有效的时空标识附加方法。

## Benchmark Construction

### A. 统一训练流程

我们着手深入研究看似不一致的性能结果的根本原因，并相应地提出一个统一的训练管道，从而能够对预测模型进行公平比较。

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312182812.png)

#### 预测性能不一致

这种不一致意味着同一解决方案的预测性能在不同论文的实验研究中表现出显著差异，即使是在相同的数据集和相同的实验设置下。为了说明这一点，表 I 汇总了一系列论文中对两种常被用作基线的解决方案（DCRNN [6] 和 Graph WaveNet [11]）在 PEMS04 和 PEMS08 数据集上的性能研究结果。所有引用的论文都采用相同的实验设置，即使用最后 12 个时间步来预测接下来的 12 个时间步，并报告预测的平均绝对误差（MAE）、均方根误差（RMSE）和平均绝对百分比误差（MAPE）结果。因此，表中的每一行都展示了不同论文的实验研究中报告的 Graph WaveNet（简称 GWNet）或 DCRNN 的性能结果。

我们可以看到，每种解决方案在不同论文中的性能差异相当大。我们还注意到，GWNet 和 DCRNN 提供了公开可用的源代码。因此，这种差异很可能是由于不同研究中采用的不同训练流程所致。此外，我们的基准测试与论文中报告的结果相比，性能有了显著提高，最大差距为 33%（PEMS04 上 GWNet 的平均绝对误差）。为了减少刚刚报告的那些虚假差异，我们对现有代码库进行了全面分析，并确定了虚假差异的三个主要来源：数据处理、训练配置和评估实现。这些方面虽然对评估结果有很大影响，但往往被忽视。

- 数据处理：在学习或推理过程中，一个关键步骤是对原始时间序列数据进行归一化。常见的方法包括最小 - 最大归一化和 Z 分数归一化，每种方法对预测性能都有不同的影响。例如，一些研究 [46] 采用最小 - 最大归一化，而大多数研究通常采用 Z 分数归一化。
- 训练配置：训练配置包括优化策略和各种训练技巧。不同的设置对优化有重大影响。例如，大多数研究 [6]、[11]、[52]、[3] 采用掩码自编码器（MAE）进行模型训练，这排除了可能对正常数值的预测产生不利影响的异常值。相比之下，一些研究 [25]、[24] 采用朴素 MAE 作为其优化函数，这往往会产生较差的结果。此外，训练技巧的结合，如梯度裁剪和课程学习，也可能对性能产生重大影响 [3]。
- 评估实施：虽然指标有精确的定义，但它们的实现方式在不同的研究中可能会有所不同，包括处理异常值和小批量计算等方面 [50]。这种差异会导致测试性能和实际性能之间出现显著偏差。

#### BasicTS + 的实现

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312183053.png)

BasicTS + 引入了统一的训练流程，如图 1 所示。这主要包括统一的数据加载器、运行器和评估组件，以解决已确定的虚假性能变化的来源。统一的数据加载器默认选择配备 z 分数归一化，这通常会产生更好的性能。此外，它还将外部时间特征（如一天中的时间）添加到原始数据中。统一运行器控制整个训练、验证和测试过程。默认情况下，我们采用掩码 MAE 作为损失函数，它通常优于朴素 MAE 和 MSE 等替代方案。

此外，统一运行器集成了课程学习和梯度裁剪等常用训练技巧。最后，统一评估组件提供了包括 MAE、RMSE、MAPE、WAPE、MSE 及其掩码版本在内的指标的标准实现。这三个组件构成了使 BasicTS + 能够支持公平分析和比较的基础。给定一个符合标准模型接口的模型，BasicTS + 可以为该模型生成评估结果。此外，BasicTS + 提供了许多可扩展性功能，例如日志系统、可定制的损失和指标，以及与各种设备的兼容性。

### B. 评估设置

评估结果应以清晰直观的方式呈现。在长时间序列预测（LTSF）中，许多研究采用诸如平均绝对误差（MAE）和均方误差（MSE）等指标，并报告基于此的预测性能。

在标准化数据（z 分数标准化）上。然而，平均绝对误差（MAE）和均方误差（MSE）表示的是绝对误差，它们可能会受到数据范围的显著影响，使得它们在解释上不太直观。此外，在标准化数据上评估预测性能可能会产生看似非常低的预测误差，这可能会误导不熟悉细节的读者。因此，一些报告预测性能的方法使得读者难以判断模型的预测性能是否令人满意。

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312183413.png)

我们提出一种实用的方法：在重新归一化的数据上进行评估，并纳入诸如平均绝对百分比误差（MAPE）和加权平均绝对百分比误差（WAPE）等额外指标。重要的长时序列预测（LTSF）模型在 ETTh1 和 ETTh2 数据集上进行归一化和重新归一化后的性能总结在表二。我们可以看到，考虑到高的 MAPE 和 WAPE 值时，在重新归一化的数据上的预测性能似乎不太令人满意，这与在归一化数据上获得的看似较低的平均绝对误差（MAE）和均方误差（MSE）值形成对比。

总之，我们在重新归一化的数据上进行评估，采用诸如 MAE、RMSE、MAPE 和 WAPE 等指标。假设 Ω 表示所有观测样本的索引， $y_{i}$ 表示第 $i$ 个实际样本， $\hat{y}_{\bar{z}}$ 表示相应的预测，这些指标定义如下。

$$\begin{array}{rlr} MAE(y, \hat{y}) & =\frac{1}{|\Omega|} \sum_{i \in \Omega}\left|y_{i}-\hat{y}_{i}\right|, RMSE(y, \hat{y})=  \sqrt{\frac{1}{|\Omega|} \sum_{i \in \Omega}\left(y_{i}-\hat{y}_{i}\right)^{2}} \\ MAPE(y, \hat{y}) & =\frac{1}{|\Omega|} \sum_{i \in \Omega}\left|\frac{y_{i}-\hat{y}_{i}}{y_{i}}\right|, WAPE(y, \hat{y})=  \frac{\sum_{i \in \Omega}\left|y_{i}-\hat{y}_{i}\right|}{\sum_{i \in \Omega}\left|y_{i}\right|} \end{array}$$

MAE 和 RMSE 指标用于量化预测准确性，而 MAPE 和 WAPE 用于消除数据单位的影响。此外，对于 M4 数据集，我们采用 sMAPE、MASE 和 OWA。为简洁起见，我们省略了它们的公式，并请感兴趣的读者参考文献[65]。

## Heterogeneity Across MTS Datasets

接下来，我们将重点关注多变量时间序列（MTS）数据集之间的异质性，并深入探讨其在解释看似矛盾的实验结果中的作用。这些实验结果表明，两种不同的技术方法中的每一种似乎都是实现提高预测准确性的最佳方法。与计算机视觉或自然语言处理中的数据集不同，后者通常具有共同的模式，而 MTS 数据集可以展示出源自不同底层系统的非常不同的模式。我们彻底研究这种异质性，并根据其时间和空间方面的特征对数据集进行分类。我们认为，不同类型的模式带来不同的解决方案挑战，这意味着特定的技术方法仅适用于特定类型的数据。忽视这种数据异质性可能导致看似相互冲突的实验结果，并导致无法提倡正确的技术方法。

### A. Temporal Aspect

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312184300.png)

我们根据时间方面将 MTS 数据集分为三种类型：具有清晰且稳定模式的数据集、具有显著分布漂移的数据集以及具有不清晰的模式的数据集。我们认为这些类型的数据集的可预测性逐渐降低。然而，量化可预测性 [66]、[67] 仍然是一个未解决的挑战。因此，我们通过可视化分析选定的数据集。具体来说，我们选择了三个典型的数据集 ——PEMS03、ETTh2 和 ExchangeRate，并在图 3 中可视化了原始时间序列。为了便于更直观的比较，我们使用 t-SNE 算法 [68] 将这些数据集的维度降低到二维，然后使用核密度估计可视化训练集和测试集的数据分布,如图 2 所示

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312184420.png)

我们可以在这些数据集中看到明显不同的模式。首先，PEMS03 记录了不同位置的城市交通流量，呈现出清晰且稳定的模式，即具有固定周期的周期性。这种模式符合城市交通的整体周期性和稳定性。其次，ETT 包含来自变压器传感器的数据。虽然它包含明显的循环模式，但周期不固定，均值在变化，表明存在分布漂移。这是因为测量值受到外部不可观察因素的影响，如天气和传感器质量。第三，ExchangeRate 记录了几种货币的汇率，显示出几乎难以察觉的模式。这一结果源于汇率主要由不可预测的因素（如经济政策）控制这一事实。因此，历史数据对预测的价值有限，特别是对于长期预测。此外，如图 2 所示，PEMS03 中训练集和测试集的数据分布具有高度相似性，而在 ETTh2 和 ExchangeRate 的情况下，未观察到这种相似性。

基于这些见解，我们认为多变量时间序列（MTS）数据固有的异质性是在比较高级神经网络 [7]、[9]、[10]、[16] 和基本神经网络 [26] 时看似矛盾的发现的关键原因。高级模型通常具有强大的数据拟合能力。当与强大的归纳偏差相结合时，这意味着此类模型对***数据分布意味着强烈的假设***。相反，由于其简单性，像线性模型 [26] 这样的基本模型***难以捕捉复杂模式，但也具有相对较弱的归纳偏差***。考虑到这些方法的不同建模能力以及 MTS 数据中的异质时间模式，我们认为：

- 当在具有稳定和清晰模式的数据集上使用时，高级模型应该能够捕捉到诸如周期性等复杂模式，而基本线性模型由于其能力有限而仍然欠拟合。
- 相比之下，当在具有显著分布漂移或不清晰模式的数据集上使用时，高级模型更有可能捕捉到仅在训练数据集中存在的虚假特征，从而面临过拟合问题。基于此讨论，我们提出以下假设：

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312184839.png)

提出 LTSF-Linear [26] 的研究忽略了数据集的异质性，并且在没有清晰且稳定模式的数据集上进行实验，导致了 Transformer 架构在多变量时间序列预测中无效的有偏差结论。我们在第六节 A3 部分对这个假设进行了实验研究。

### B. Spatial Aspect

与易于观察的时间模式不同，空间依赖性更难把握，并且也更难找到明确的指标来根据数据集的空间方面对其进行区分。许多研究将空间模式松散地解释为时间序列之间的相互作用，并使用图卷积网络（GCNs）对其进行建模，而没有深入讨论如何理解和量化这些模式。幸运的是，最近的两项研究 ST-Norm [31] 和 STID [30] 指出，空间维度中样本的不可区分性（简称空间不可区分性）触及了空间依赖性的本质。接下来，我们采用这个想法，并首次设计定量指标，根据空间方面区分异构数据集。具体来说，我们将多变量时间序列数据集分为两类：具有显著空间不可区分性的数据集和不具有显著空间不可区分性的数据集，然后讨论何时以及如何对空间依赖性进行建模。

在多变量时间序列（MTS）预测中，样本是通过大小为 $T_p + T_f$ 的滑动窗口生成的，其中 $T_p$ 和 $T_f$ 分别表示历史数据和未来数据的长度。空间不可区分性指的是，对于给定的时刻 $t$，我们可能会生成许多具有相似历史数据但不同未来数据的样本。简单的回归模型（例如，多层感知器（MLP）、循环神经网络（RNN））无法基于相似的历史数据预测不同的未来数据。换句话说，它们无法区分历史样本[30]。基于这个概念，我们提出以下量化指标：

$$\begin{align*}
r_1 &= \frac{\sum_{t,i,j} \mathbb{I}( \mathbf{A}_{t,i,j}^P > e_u \land \mathbf{A}_{t,i,j}^F < e_l )}{T \cdot N \cdot N}, \quad
r_2 = \frac{\sum_{t,i,j} \mathbb{I}( \mathbf{A}_{t,i,j}^P > e_u \land \mathbf{A}_{t,i,j}^F < e_l )}{\sum_{t,i,j} \mathbb{I}( \mathbf{A}_{t,i,j}^P > e_u )}\\
\mathbf{A}_{t,i,j}^P &= \frac{\mathbf{X}_{i,t - T_p:t}^j \cdot \mathbf{X}_{j,t - T_p:t}^j}{\|\mathbf{X}_{i,t - T_p:t}^j\|\|\mathbf{X}_{j,t - T_p:t}^j\|}, \quad
\mathbf{A}_{t,i,j}^F = \frac{\mathbf{X}_{i,t:t + T_f}^j \cdot \mathbf{X}_{j,t:t + T_f}^j}{\|\mathbf{X}_{i,t:t + T_f}^j\|\|\mathbf{X}_{j,t:t + T_f}^j\|}
\end{align*}$$

#### 直观理解
对于一个有 $T$ 个时间步和 $N$ 个样本的数据集，我们构建两个相似性矩阵 $\mathbf{A}^P, \mathbf{A}^F \in \mathbb{R}^{T\times N\times N}$ ，表示成对相似性，即各个时间步的样本之间的相似性。具体来说， $\mathbf{A}_{t,i,j}^P$ 表示时刻 $t$ 时时间序列 $i$ 和 $j$ 在历史时间步的相似性，$\mathbf{A}_{t,i,j}^F$ 表示相应的未来时间步的相似性。利用这些矩阵，我们将总样本数定义为 $T \cdot N \cdot N$ ，历史相似样本数为 $\sum_{i,j,t} \mathbb{I}( \mathbf{A}_{t,i,j}^P > e_u )$ ，不可区分样本数为 $\sum_{i,j,t} \mathbb{I}( \mathbf{A}_{t,i,j}^P > e_u \land \mathbf{A}_{t,i,j}^F < e_l )$ 。这里， $e_u = 0.9$ 和 $e_l = 0.5$ 分别是相似性的上限和下限阈值。指示函数 $\mathbb{I}(\cdot)$ 在条件满足时返回\(1\)，否则返回\(0\)。然后我们定义两个指标： $r_1$ ，不可区分样本数与总样本数的比率； $r_2$ ，不可区分样本数与具有相似历史数据的样本数的比率。这些指标提供了互补的见解： $r_1$ 有助于判断不可区分性是否是提高预测性能的主要障碍，而 $r_2$ 则对不可区分程度进行了更细致的评估。

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312190736.png)

我们计算了11个常见数据集的上述两个指标。结果如图4所示。我们可以清楚地看到，ETT、电力（ELC）、汇率（ER）和天气数据集的 $r_1$ 和 $r_2$ 值非常低，而METR - LA（LA）、PEMS - BAY（BAY）、PEMS04（04）和PEMS08（08）数据集的 $r_1$ 和 $r_2$ 值则明显更高。有趣的是，尽管这两组不同的数据集格式完全相同，但在实证研究中很少同时使用它们。ETT、电力、汇率和天气数据集常用于长期时间序列预测（LTSF）研究，在这些研究中，空间依赖性并非主要关注点。此外，METR - LA、PEMS - BAY、PEMS04和PEMS08数据集则用于时空预测（STF）研究，其中空间依赖性是核心内容。

基于上述见解，我们来讨论何时以及如何对空间依赖性进行建模。首先，对于不存在显著空间不可区分性的数据集，没有迫切必要对空间依赖性进行建模，强行建模空间依赖性甚至可能会降低性能。其次，对于存在显著空间不可区分性的数据集，通过解决空间不可区分性问题来对空间依赖性进行建模可以提升性能。为了更具体地探讨如何实现，我们来看时空图神经网络（STGNNs）[11, 6]、时空归一化方法（ST - Norm）[31]和时空身份附加方法（STID）[30]的相关研究。
- 首先，时空图神经网络中的图卷积网络（GCNs）[11, 6]通常依赖于符合同质性假设的图结构[70, 71]，在这种假设下，相连的节点往往具有相似的标签 。因此，具有相似历史数据但不同未来数据（即标签）的节点（也就是时间序列）往往不会相连。鉴于这样的图结构，图卷积网络在处理具有相似历史数据的时间序列时表现不佳。
- 其次，时空归一化方法（ST - Norm）[31]通过分别细化输入数据背后的高频成分和局部成分，在空间维度上对数据进行归一化，这也使得历史数据具有可区分性。
- 第三，时空身份附加方法（STID）[30]提出了一个简单而有效的想法，即为每个时间序列附加一个可训练的空间标识，以便区分相似的历史数据。基于上述讨论，我们提出以下假设：
  
![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312191117.png)

## Experiment

### 高级神经网络与基础神经网络
本小节研究高级模型（例如 Transformer）与基本模型（例如线性模型）的性能，并评估 V-A 节中的假设。我们考虑四个数据集：PEMS04 和 PEMS08，它们呈现出清晰且稳定的模式；以及 ETTh2 和 ETTm2，它们表现出显著的分布漂移或不清晰的模式。基于 LTSF-Linear 研究 [26] 选择了六个基线模型。

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312191752.png)

Informer、Autoformer 和 FEDformer 是先进的 Transformer 模型，而 Linear、DLinear 和 NLinear 是基本的线性模型。它们都遵循第六节 A3 中描述的 LTSF 设置。我们报告平均绝对误差（MAE）、均方根误差（RMSE）和加权平均百分比误差（WAPE）。此外，我们计算了最佳先进模型和基本模型之间的性能差距，如表三所示。

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312191833.png)  

首先，在具有清晰且稳定模式的数据集上，高级模型通常会以非常大的优势（绿色背景）胜过基础模型。其次，在具有分布漂移或不清晰模式的数据集上，基础模型始终优于高级模型。这种预测性能上的差距乍一看可能令人困惑。为了直观地理解原因，我们在 PEMS08 和 ETTh2 数据集上可视化 FEDformer 和 DLinear 在不同 epoch 数量下的平均绝对误差（MAE）—— 见图 5。在 PEMS08 上，FEDformer 的训练、验证和测试 MAE 从相似的值开始并持续下降。相比之下，DLinear 的 MAE，甚至是训练 MAE，都不会随着 epoch 的增加而降低，这表明 DLinear 存在欠拟合。接下来，在 ETTh2 数据集上，FEDformer 的训练 MAE 持续下降，而其验证和测试 MAE 在达到 2 个 epoch 时就开始增加，这表明 FEDformer 存在严重的过拟合。这些结果与 V-A 节中的假设一致。

我们将研究结果总结如下。首先，得益于强大的建模能力，当数据具有清晰且稳定的模式时，高级神经网络远比基本神经网络有效。其次，归纳偏置较少的模型 [80]（例如基于多层感知机或原始 Transformer [16] 的模型）在没有明确模式时通常表现更好。此外，尽管一些最近的解决方案被定位为通用的多变量时间序列预测解决方案，但我们认为有效的通用解决方案应首先在具有清晰模式的数据上表现良好，然后还应考虑其在模式不太清晰的时间序列上的性能。

### Delving into Spatial Dependencies

在这里，我们讨论何时以及如何对空间依赖性进行建模，并评估第五节 B 部分中的假设。我们选择了四个数据集，其中 METR-LA（LA）和 PEMS-BAY（BAY）具有高度的空间不可区分性（见第五节 B 部分中的 $r_{1}$ 和 $r_{2}$ ），而 ExchangeRate（ER）和 ETTm1 具有非常低的空间不可区分性。我们选择了两个采用不同方法对空间依赖性进行建模的基线模型：STID [30] 和 AGCRN [48]。STID 设计了可训练的空间标识嵌入，而 AGCRN。

采用基于图卷积网络（GCN）的学习模块。此外，我们从它们中的每一个中去除空间建模组件，得到没有空间标识的变体 STID∗以及将邻接矩阵设置为单位矩阵的变体 AGCRN∗。

![1](https://picgo-for-paper-reading.oss-cn-beijing.aliyuncs.com/img/20250312192822.png)

结果如表格 IV 所示。在具有显著空间不可区分性的数据集上，同时使用可训练的空间身份嵌入和 GCN（图卷积网络）可以带来显著的性能提升。相反，在空间不可区分性较低的数据集上，添加这些空间建模组件会降低性能，这表明在这些数据集上对空间依赖性（或称为跨维度依赖性）进行建模并非必要。

基于上述讨论，我们得出结论：空间不可区分性是空间依赖性的一个强有力指标，并且我们并不总是需要对空间依赖性进行建模。当数据中存在高度的空间不可区分性时，采用空间建模方法（例如图卷积网络、归一化 [31] 和空间恒等 [30]）是有意义的，以提高性能。相反，在空间不可区分性较低的数据集上，设计空间建模模块需要格外小心，因为这可能会导致性能下降。
